<!DOCTYPE HTML>
<html lang="en"><head>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-4NVT6KB8YN"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-4NVT6KB8YN');
</script>
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="author" content="Yanhong Zhao">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="keywords" content="Yanhong Zhao, Computer Vision, Deep Learning, Generative Models">
  <meta name="description" content="Zola's homepage">
  
  <style>
    body {background-color: white;}
  </style>
  <title>Bin Ren</title>
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/jpg" href="image/bulb.jpg">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">

<!-- profile photo -->
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="image/photo_binren.png"><img style="max-width:100%" alt="profile photo" src="image/photo_binren.png" class="hoverZoomLink"></a>

              <p style="text-align:center">
                <a href="mailto:bin.ren@unitn.it">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=Md9maLYAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/Amazingren">Github</a> &nbsp/&nbsp
                <a href="https://twitter.com/Hello_RenBin">Twitter</a>
              </p>
            </td>

<!-- bio -->

            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Bin Ren (任斌)</name>
              </p> 
              <p>I am a second-year Ph.D. student in the <a href="https://www.phd-ai.it/en/359-2/#"> Italian National Artificial Intelligence Program</a> co-organized by <a href="https://www.unipi.it/index.php/english">the University of Pisa, Italy</a>, and <a href="https://www.unitn.it/en">the University of Trento, Italy</a>. 
                 I am in the <a href="http://mhug.disi.unitn.it/#">Multimedia and Human Understanding Group (MHUG)</a> advised by <a href="https://scholar.google.com/citations?user=stFCYOAAAAAJ&hl=en">Prof. Dr. Nicu Sebe</a> and <a href="https://scholar.google.com/citations?user=OM3sZEoAAAAJ&hl=en">Prof. Dr. Rita Cucchiara</a>.
                 Currently, I am an academic visiting student at the Computer Vision Lab (CVL) of ETH Zürich, and under the supervision of <a href="https://scholar.google.com/citations?user=TwMib_QAAAAJ&hl=en">Prof. Dr. Luc Van Gool</a>.
              </p>
              <p> My research interests lie in the intersection of computer vision, deep learning. 
                  Recently I work on low-level computer vision tasks and exploring the usage of the generative models. 
	     </p>

       <p> Prior to my Ph.D. studies, I received my master's degree (2021) under the supvision of <a href="https://scholar.google.com/citations?user=4CQKG8oAAAAJ&hl=en">Prof. Hong Liu</a> in computer applied technology at the School of Electronics and Computer Engineering, <a href="https://english.pku.edu.cn/">Peking University, China</a>, 
           and received my B.Eng. degree (2016) in the College of Mechanical and Electrical Engineering, <a href="https://en.csu.edu.cn/">Central South University, China</a>. 
              </p>

          </tr>
        </tbody></table>

<!-- logos -->

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:20%;vertical-align:middle">
                <a href="https://ethz.ch/en.html"> <img src="image/eth_logo.png" alt="eth_logo" style="max-width:100%"></a>
            <td style="padding:20px;width:20%;vertical-align:middle">
                <a href="https://www.unipi.it/index.php/english"> <img src="image/unipi.png" alt="unipi_logo" style="max-width:100%"></a>
            <td style="padding:20px;width:20%;vertical-align:middle">
                <a href="https://www.unitn.it/en"> <img src="image/unitn.png" alt="unitn_logo" style="max-width:100%"></a>
            </td>
            <td style="padding:20px;width:20%;vertical-align:middle">
                <a href="https://english.pku.edu.cn/"> <img src="image/pku.png" alt="pku_logo" style="max-width:100%"></a>
            </td>
            <td style="padding:20px;width:20%;vertical-align:middle">
                <a href="https://en.csu.edu.cn/"> <img src="image/csu.png" alt="csu_logo" style="max-width:100%"></a>
            </td>
            </tr>
        </tbody></table>

<!-- News -->

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>News</heading>
            </td>
          </tr>
        </tbody></table>

        <table width="90%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
	<td>
	<ul>
    <li>2024/03: I joined INSAIT in Sofia as a research intern.
    <li>2024/02: We are organizing the NTIRE2024 Efficient Super-Resolution Challenge! Come and join via: https://cvlai.net/ntire/2024/!
    <li>2024/01: Our paper "A survey on 3d skeleton-based action recognition using learning method" has been accepted as oral by Cyborg and Bionic Systems (CBS) in 2024.
    <li>2023/11: Our paper "Modiff: Action-conditioned 3d motion generation with denoising diffusion probabilistic models" has been accepted as oral by ICASSP24 in 2023.
    <li>2023/08: Our paper "Spatio-Temporal Graph Diffusion for Text-Driven Human Motion Generation" has been accepted as oral by BMVC in 2023.
    <li>2023/08: Our paper "Cloth Interactive Transformer for Virtual Try-On" has been accepted by ACM ToMM in 2023.
    <li>2023/08: I joined the Computer Vision Lab (CVL) of ETH Zürich in Switzerland as a 6-month academic visiting Ph.D. Student.
    <li>2023/03: Our paper "Masked Jigsaw Puzzle: A Versatile Position Embedding for Vision Transformers" has been accepted by CVPR2023.
    <li>2023/02: Our paper "PI-Trans: Parallel-ConvMLP and Implicit-Transformation Based GAN for Cross-View Image Translation" has been accepted by ICASSP2023.
    <li>2022/10: Our paper "Deep Unsupervised Key Frame Extraction for Efficient Video Classification" has been accepted by TOMM in 2022.
    <li>2021/10: Our paper "Cascaded Cross MLP-Mixer GANs for Cross-View Image Translation" has been accepted by BMVC2021 as oral.
    <!-- <li>2022/07: My personal WebPage Comes out! -->
	</ul>
	</td>
          </tr>
        </tbody></table>

<!-- Activities -->

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Activities</heading>
            </td>
          </tr>
        </tbody></table>

        <table width="90%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
	<td>
	<ul>
    <li>2023/09: I will join the ELLIS Summer School on Large-Scale AI for Research and Industry, in Modena, Italy!
    <li>2022/07: I joined the ICVSS2022, in Sicily, Italy!
    <li>2022/07: I joined The first Italian National AI&Society Ph.D. Summer School, in Pisa, Italy.
	</ul>
	</td>
          </tr>
        </tbody></table>

        
<!-- Selected Publications -->

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications</heading>
              <p>
            </td>
          </tr>
        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr onmouseout="tomm1_stop()" onmouseover="tomm1_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='tomm1_image'>
                <img src='image/cit_tomm23.jpg' width="100%" height="75%">
	        </div>
                <img src='image/results_tomm23.jpg' width="100%" height="75%">
              </div>
              <script type="text/javascript">
                function tomm1_start() {
                  document.getElementById('tomm1_image').style.opacity = "1";
                }
                function tomm1_stop() {
                  document.getElementById('tomm1_image').style.opacity = "0";
                }
                tomm1_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2104.05519.pdf">
                <papertitle>Cloth Interactive Transformer for Virtual Try-On</papertitle>
              </a>
              <br>
              <strong>Bin Ren</strong>, 
              <a href="https://scholar.google.com/citations?user=9zJkeEMAAAAJ&hl=en&oi=ao">Hao Tang</a>,   
              <a href="https://scholar.google.com/citations?user=dv9BKcMAAAAJ&hl=en&oi=ao">Fanyang Meng</a>, 
              <a href="https://scholar.google.com/citations?user=gU9chAwAAAAJ&hl=en&oi=ao">Runwei Ding</a>, 
              <a href="https://scholar.google.com/citations?user=kPxa2w0AAAAJ&hl=en&oi=ao">Philip Hs Torr</a>, 
              <a href="https://scholar.google.com/citations?user=stFCYOAAAAAJ&hl=en&oi=ao">Nicu Sebe</a>
              <br>
              <em>Transactions on Multimedia Computing Communications and Applications (ACM ToMM)</em>, 2023
              <br>
              <a href="https://arxiv.org/pdf/2104.05519.pdf">paper</a> /
              <a href="https://github.com/Amazingren/CIT">code</a> /
              <a href="bib/ren_tomm23_cit.txt">bibtex</a> 
              <p></p>
              </p>
            </td>
          </tr>	

        <tr onmouseout="cvpr1_stop()" onmouseover="cvpr1_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='cvpr1_image'>
                <img src='image/projection_cvpr23.jpeg' width="100%" height="75%">
	        </div>
                <img src='image/mjp_cvpr23.jpeg' width="100%" height="75%">
              </div>
              <script type="text/javascript">
                function cvpr1_start() {
                  document.getElementById('cvpr1_image').style.opacity = "1";
                }
                function cvpr1_stop() {
                  document.getElementById('cvpr1_image').style.opacity = "0";
                }
                cvpr1_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2205.12551.pdf">
                <papertitle>Masked Jigsaw Puzzle: A Versatile Position Embedding for Vision Transformers</papertitle>
              </a>
              <br>
              <strong>Bin Ren</strong>, 
              <a href="https://scholar.google.com/citations?user=P8qd0rEAAAAJ&hl=en&oi=ao">Yahui Liu</a>, 
              <a href="https://scholar.google.com/citations?user=Uza2i10AAAAJ&hl=en&oi=ao">Yue Song</a>, 
              <a href="https://scholar.google.com/citations?user=aSJcgQMAAAAJ&hl=en&oi=ao">Wei Bi</a>, 
              <a href="https://scholar.google.com/citations?user=OM3sZEoAAAAJ&hl=en&oi=ao">Rita Cucchiara</a>, 
              <a href="https://scholar.google.com/citations?user=stFCYOAAAAAJ&hl=en&oi=ao">Nicu Sebe</a>, 
              <a href="https://scholar.google.com/citations?user=k4SdlbcAAAAJ&hl=en&oi=ao">Wei Wang</a>
              <br>
              <em>Computer Vision and Pattern Recognition (CVPR)</em>, 2023
              <br>
              <a href="https://arxiv.org/pdf/2205.12551.pdf">paper</a> /
              <a href="https://github.com/yhlleo/MJP">code</a> /
              <a href="bib/ren_cvpr23_mjp.txt">bibtex</a> 
              <p></p>
              </p>
            </td>
          </tr>	
		
          <tr onmouseout="icassp1_stop()" onmouseover="icassp1_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='icassp1_image'>
                <img src='image/framework_pitrans_icassp23.jpeg' width="100%" height="75%">
	        </div>
                <img src='image/simpleShow_pitrans_icassp23.jpeg' width="100%" height="75%">
              </div>
              <script type="text/javascript">
                function icassp1_start() {
                  document.getElementById('icassp1_image').style.opacity = "1";
                }
                function icassp1_stop() {
                  document.getElementById('icassp1_image').style.opacity = "0";
                }
                icassp1_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2207.04242.pdf">
                <papertitle>PI-Trans: Parallel-ConvMLP and Implicit-Transformation Based GAN for Cross-View Image Translation</papertitle>
              </a>
              <br>
              <strong>Bin Ren</strong>, 
              <a href="https://scholar.google.com/citations?user=9zJkeEMAAAAJ&hl=en&oi=ao">Hao Tang</a>, 
              <a href="https://scholar.google.com/citations?user=KBZ3zrEAAAAJ&hl=en&oi=ao">Yiming Wang</a>, 
              <a href="https://scholar.google.com/citations?user=XKGZhEcAAAAJ&hl=en&oi=ao">Xia Li</a>, 
              <a href="https://scholar.google.com/citations?user=k4SdlbcAAAAJ&hl=en&oi=ao">Wei Wang</a>,
              <a href="https://scholar.google.com/citations?user=stFCYOAAAAAJ&hl=en&oi=ao">Nicu Sebe</a> 

              <br>
              <em>International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, 2023
              <br>
              <a href="https://arxiv.org/pdf/2207.04242.pdf">paper</a> /
              <a href="https://github.com/Amazingren/PI-Trans">code</a> /
              <a href="bib/ren_icassp23_pitrans.txt">bibtex</a> 
              <p></p>
              </p>
            </td>
          </tr>	

        </tbody></table>

<!-- copyright -->

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;background-color:PapayaWhip"><tbody>
          <tr>
	   <td style="text-align:center">
	     <p> Web template &#169; <a href="https://github.com/jonbarron/website" target="_blank" rel="external nofollow noopener noreferrer">this</a>. &nbsp All content &#169; Bin Ren<br> 
	     <span id="busuanzi_container_site_pv">This page has been visited <span id="busuanzi_value_site_pv"></span>&nbsp;times </span> 
	    <span id="busuanzi_container_site_uv">by <span id="busuanzi_value_site_uv"></span></span>&nbsp;people.</p>
           </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
